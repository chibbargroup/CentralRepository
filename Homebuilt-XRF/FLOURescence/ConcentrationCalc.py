'''
Concentration Calculator
Written by J. Hayes, Last Editted 1/25/2017

Purpose: Calculate the concentrations of each element in a sample using the calibration 
curves generated by the LinearRegression.py file

Takes as inputs:
1) File directory with normalized peak area files
2) File with calibration curve information
3) Directory to save results

Returns:
Generates 2 files: 
1) concentrations.csv - The raw concentrations for each sample position
2) avg_conc.csv - The average concentration for that sample

Generally intended to be run as part of the FLOURescence software package
'''

from os import listdir
from os.path import isfile, join
import numpy as np
import pandas as pd

#Opens and combines the data
def File_Combiner(norm_file_dir):
	data = pd.DataFrame()
	#opens all the data-containing files and puts them into one dataframe
	all_files = all_files = [f for f in listdir(norm_file_dir) if isfile(join(norm_file_dir, f))]
	for f in all_files:
		df = pd.read_csv(join(datafiledir,f), index_col = 0)
		data = pd.concat([data,df], axis = 1)
	data = data.drop('Io')
	return data 

#Removes the spectra collected on empty spaces and calibration samples
def Column_Cleaner(data):
	empty_aliases = ['empty', 'Empty', 'x', 'X', 'blank', 'Blank'] #Can be modified as necessary
	for column in set(data.columns): #Note: Use set because del data[column] will remove all instances of that column value
		column_read = column.split('.')[0]	
		if column_read in empty_aliases:
			del data[column]
		elif "Cal " in column:
			del data[column]
	return data

#Renames the columns so that there are no replicates; name format: XXX.# (XXX=Original name)
def Replicate_Renamer(data):
	column_list = list(data.columns)
	new_names = []
	for column in column_list:
		if '.' not in column:
			column = column + '.1'
		if column not in new_names:
			new_names.append(column)
		else:
			i = 1
			rename = True
			while rename:
				if '.' in column:
					column = column.split('.')[0]				
				column = column + '.%s' %i
				if column not in new_names:
					new_names.append(column)
					rename = False
				else:
					i += 1
	data.columns = new_names
	return data

#Combines and reformats the normalized peakfit data set using the previous functions
def Data_Formatter(norm_file_dir):
	df = File_Combiner(datafiledir)
	df = Column_Cleaner(df)
	df = Replicate_Renamer(df)
	return(df)

def Concentration_Calculator(data, calibration_file):
	cal_curves = pd.read_csv(calibration_file, index_col = 0)
	for element in data.index:
		data.ix[element] = (data.ix[element]-cal_curves[element]['intercept'])/cal_curves[element]['slope']
	return(data)

def Data_Averager(data):
	averaged_data = pd.DataFrame()
	
	#Make list of each individual sample
	sample_list = []
	for column in data:
		column = column.split('.')[0]
		sample_list.append(column)
	sample_list = set(sample_list)

	#Average all the data columns containing data from that sample 
	for sample in sample_list:
		column_positions = [i for i,j in enumerate(data.columns) if sample == j.split('.')[0]]
		sample_data = data.iloc[:,column_positions]
		sample_average = sample_data.sum(axis=1)/len(column_positions)
		sample_average = sample_average.rename(sample)
		averaged_data = pd.concat([averaged_data, sample_average], axis = 1)
	return(averaged_data)

def Data_Analyzer(norm_file_dir, calibration_file, save_dir):
	#Run the analysis
	df = Data_Formatter(norm_file_dir)
	raw_concs = Concentration_Calculator(df, calibration_file)
	avg_concs = Data_Averager(raw_concs)

	#Save the data
	conc_file_name = join(save_dir, 'concentrations.csv')
	avg_file_name = join(save_dir, 'avg_concentrations.csv')
	raw_concs.to_csv(conc_file_name)
	avg_concs.to_csv(avg_file_name)


datafiledir = 'C:/Users/John/Desktop/Test/FIT'
calinfofile = 'C:/Users/John/Desktop/Test/Output/Calibration_Curves/CalibrationCurvesOut.csv'
calcomb = 'C:/Users/John/Desktop/Test/Calibration_Curves/CombinedCals.csv'
cal_concs = 'C:/Users/John/Desktop/Test/Calibration_Curves/concentrations.npy'
file_out = 'C:/Users/John/Desktop/Test/'

Data_Analyzer(datafiledir, calinfofile, file_out)